{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pixace-demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeew/pjDmeO44rsSNdQyXH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnubob/pixace/blob/main/examples/pixace_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BILqhusSZYa"
      },
      "source": [
        "# Pixace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zS6Bz2N6QO-"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "\r\n",
        "# download and install the latest version of pixace\r\n",
        "!sudo pip install -qqq -U \\\r\n",
        "  https://github.com/vishnubob/pixace/archive/main.zip\r\n",
        "  \r\n",
        "import pixace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INs70ura6pvo"
      },
      "source": [
        "# download the animalfaces model\r\n",
        "\r\n",
        "pixace.download_model(model_name=\"animalfaces\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYTnTjIJa04I"
      },
      "source": [
        "# generate a new animal face from scratch\r\n",
        "\r\n",
        "predictor = pixace.get_predictor(model_name=\"animalfaces\")\r\n",
        "predictor.predict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF-bBmm7Wtxb"
      },
      "source": [
        "# use two images from the web as image prompts\r\n",
        "\r\n",
        "url_1 = \"https://github.com/vishnubob/pixace/raw/main/examples/prompts/prompt_1.jpg\"\r\n",
        "url_2 = \"https://github.com/vishnubob/pixace/raw/main/examples/prompts/prompt_2.jpg\"\r\n",
        "prompts = [url_1, url_2]\r\n",
        "predictor.predict(prompts=prompts, cut=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdZoseHSJGLA"
      },
      "source": [
        "# download emoji image set\r\n",
        "# split images into training sets and validation sets\r\n",
        "\r\n",
        "import os\r\n",
        "import io\r\n",
        "import shutil\r\n",
        "import random\r\n",
        "\r\n",
        "from zipfile import ZipFile\r\n",
        "import requests\r\n",
        "\r\n",
        "def download_and_extract(url, dest=\"data\"):\r\n",
        "  resp = requests.get(url)\r\n",
        "  fh = io.BytesIO(resp.content)\r\n",
        "  fh.seek(0)\r\n",
        "  with ZipFile(fh) as arc:\r\n",
        "    arc.extractall(dest)\r\n",
        "\r\n",
        "def split_data(path=None, dest=None, ratio=0.05):\r\n",
        "  assert ratio > 0 and ratio < 1\r\n",
        "  files = os.listdir(path)\r\n",
        "  random.shuffle(files)\r\n",
        "  t_cnt = int(round(len(files) * (1 - ratio)))\r\n",
        "  t_set = files[:t_cnt]\r\n",
        "  v_set = files[t_cnt:]\r\n",
        "  parts = ((\"train\", v_set), (\"val\", t_set))\r\n",
        "  \r\n",
        "  new_paths = {}\r\n",
        "  for (name, dataset) in parts:\r\n",
        "    out = os.path.join(dest, name)\r\n",
        "    new_paths[name] = out\r\n",
        "    if os.path.isdir(out):\r\n",
        "      shutil.rmtree(out)\r\n",
        "    os.makedirs(out, exist_ok=True)\r\n",
        "    for src in dataset:\r\n",
        "      tgt = os.path.join(out, os.path.split(src)[-1])\r\n",
        "      os.symlink(src, tgt)\r\n",
        "  msg = f\"Split {len(files)} images: {len(t_set)} training, {len(v_set)} validation\"\r\n",
        "  print(msg)\r\n",
        "  return new_paths\r\n",
        "\r\n",
        "\r\n",
        "url = \"https://github.com/googlefonts/noto-emoji/archive/master.zip\"\r\n",
        "weight_dir = \"model-weights\"\r\n",
        "out = \"emoji-data\"\r\n",
        "images = f\"{out}/noto-emoji-master/png/128\"\r\n",
        "\r\n",
        "os.makedirs(weight_dir, exist_ok=True)\r\n",
        "download_and_extract(url, out)\r\n",
        "dataset_paths = split_data(path=images, dest=out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjmttBJaNywg"
      },
      "source": [
        "# train a new model on the emoji image dataset\r\n",
        "# this training run will require ~20 minutes to run\r\n",
        "# we will dial down the image resolution to 16x16 and reduce the\r\n",
        "# bitdepth of color to HSV 433\r\n",
        "#\r\n",
        "# there is a tensorboard below.  after a few minutes of training\r\n",
        "# you can hit the refresh button on the top right of the tensorboard\r\n",
        "# visualized samples from training are available by\r\n",
        "# clicking on the tensorboard images tab \r\n",
        "\r\n",
        "%tensorboard --logdir model-weights\r\n",
        "\r\n",
        "trainer = pixace.get_trainer(\r\n",
        "    model_name=\"emoji_16_433\",\r\n",
        "    image_size=16,\r\n",
        "    bitdepth=(4, 3, 3)\r\n",
        ")\r\n",
        "trainer.train(\r\n",
        "    steps_per_epoch=200,\r\n",
        "    images=dataset_paths[\"train\"],\r\n",
        "    val_images=dataset_paths[\"val\"],\r\n",
        "    batch_size=64,\r\n",
        "    n_epochs=5\r\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMwZUBgnOR66"
      },
      "source": [
        "# use your new emoji model to generate new emojis\r\n",
        "#\r\n",
        "# Note: we haven't given the model enough time to converge, so\r\n",
        "# don't expect these predictions to look amazing\r\n",
        "# however, you should see hints of emoji structure and color\r\n",
        "#\r\n",
        "# the trainer above is smart enough to pick up where it left off, making it\r\n",
        "# easy to continue to train your model.  try it! \r\n",
        "\r\n",
        "predictor = pixace.get_predictor(model_name=\"emoji_16_433\", image_size=16, bitdepth=(4,3,3))\r\n",
        "predictor.predict(batch_size=4, temperature=(1, 1, 1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9BQmuPIsVYl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}